{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b39582c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a3aa3d7237fe45cfc9db695205b7492b",
     "grade": false,
     "grade_id": "01a-intro",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "# Assignment 01a - Data Visualization\n",
    "\n",
    "\n",
    "## Goals\n",
    "You can load and visualize measurements from the dataset:\n",
    "  * you can visualize the coordinate frames of the vehicle mounted sensors (3D axes of camera, LiDAR, radar)\n",
    "  * **MP only**: you can visualize LiDAR point clouds in the camera image\n",
    "  * **MP only**: you can visualize radar measurements in the camera image\n",
    "  * you can visualize the vehicle pose over time in a world-static frame (3D axes)\n",
    "\n",
    "In addition, you will be able to work with\n",
    "  * annotated 3D object labels (such as projecting them into the camera image)\n",
    "  * ground plane models\n",
    "\n",
    "We provide you with a dataset recorded from a vehicle with different sensors (camera, LiDAR, radar, pose (odometry)) which provide measurements over time. Each sensor lives in a coordinate frame which defines its rotation and translation with respect to another frame, e.g., how are camera and LiDAR positioned relative to each other.\n",
    "\n",
    "Please make use of the classes for dataset access you got familiar with in the practica, namely `Dataset`, `Sequence` and `Measurements`, and the functions you implemented in Practicum 1, such as `project_points(camera_projection_matrix, points)`.\n",
    "There is also a recap in this notebook. \n",
    "We can import it within this notebook using `from ipynb.fs.defs.practicum1 import project_points`.\n",
    "If there are technical issues (e.g. with `ipynb` import, you can also copy over code from your practica, but please mark it as such.\n",
    "\n",
    "## Input\n",
    "Custom sequence from dataset with defined `start_index` and `end_index`\n",
    "\n",
    "## Output\n",
    "Plots and visualizations within this notebook.\n",
    "No additional files.\n",
    "\n",
    "## Grading\n",
    "You will get credits for the correct visualizations and answers.\n",
    "Most answers will be autograded, so please stick to the instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0714c18",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "295af8a17690e30ae711a73abc7773d7",
     "grade": false,
     "grade_id": "import-ipython-magic",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.0a\n",
    "# some magic to ease implementing within jupyter notebooks\n",
    "from IPython import get_ipython\n",
    "\n",
    "ipython = get_ipython()\n",
    "if ipython:\n",
    "    ipython.magic(\"load_ext autoreload\")\n",
    "    ipython.magic(\"autoreload 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b07c1e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6881e01e02f0335271e38696c2ff3fe4",
     "grade": false,
     "grade_id": "cell-dbdce35b53dc43a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The next cell loads the variable `COURSE_TYPE` that you configured in `fa_00_overview.ipynb`. This notebook assignment contains parts that are MP and IV-specific. Using this variable, certain parts of this notebook are automatically skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d2648f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e9c7e68717e6389eba879da468a389d",
     "grade": false,
     "grade_id": "set-course-type",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.0b\n",
    "from ipynb.fs.defs.fa_00_overview import COURSE_TYPE, RUN_ALL\n",
    "print('Course type:', COURSE_TYPE)\n",
    "print('Run both MP and IV implementations:', RUN_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a134d6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4c2a059eae7f8d8dadec24d87282314",
     "grade": true,
     "grade_id": "assert-course-type",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.0c\n",
    "assert COURSE_TYPE == 'IV' or COURSE_TYPE == 'MP'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d9cfb5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ec1af6610ef2d5db05fa479e6a1b087",
     "grade": false,
     "grade_id": "classes-recap",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Recap on the classes `Dataset`, `Sequence`, `Measurements`\n",
    "You will work with data from the View-of-Delft dataset. This dataset was recently recorded in Delft from a moving vehicle equipped with various sensors. It was collected by researchers from the Intelligent Vehicles group at TU Delft. You will work with a subset of the dataset: A short sequence and only the stereo camera, LiDAR, and radar sensors.\n",
    "\n",
    "You have already worked with the sequence loader in practicum 1, but still we will recap some of the concepts. \n",
    "\n",
    "* The `Dataset` class encapsulates all measurements of all sensors over time for the View-of-Delft dataset\n",
    "* The `Sequence` is a subset of the dataset encapsulating all measurements of all sensors over time for a subset of time (defined by `start_index` and `end_index`).\n",
    "* The `Measurements` class encapsulates the measurements of all sensors for a single point in time.\n",
    "\n",
    "See the code below for the an exemplaric use and the available getters of the `Measurements` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff40c02",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a87ec86b1d79c099d7e521052c99301e",
     "grade": false,
     "grade_id": "import-data",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.0d\n",
    "from common.sequence_loader import Dataset\n",
    "\n",
    "dataset = Dataset()  # the view-of-delft dataset\n",
    "sequence = dataset.get_custom_sequence(1430, 1431)  # a subset of two timesteps of the dataset\n",
    "measurements = next(iter(sequence))  # first measurements object within the sequence\n",
    "\n",
    "# show getters of dataset\n",
    "sorted([method for method in dir(measurements) if method.startswith(\"get_\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844d6969",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aaf8bdf7c8704b34a5f2a2e62d7f0c8a",
     "grade": false,
     "grade_id": "function-descriptions",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "* The `get_T_*` methods return homogeneous transforms between sensor frames according to the conventions recapitulated further below.\n",
    "* The `get_*_points` methods return points in 4xN homogenenous coordinates\n",
    "* The `get_*_image` methods return the camera images represented as NumPy arrays\n",
    "* The `get_camera_projection_matrix` methods returns the 3x4 projection matrix for the left camera\n",
    "* The `get_right_camera_projection_matrix` methods returns the 3x4 projection matrix for the right camera\n",
    "* The `get_disparity` method returns the disparity map (based on stereo images)\n",
    "* The `get_ground_plane` method returns the ground plane in the LiDAR frame and will be covered later in this notebook.\n",
    "\n",
    "Feel free to explore the data obtained by the other getters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dac3d75",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a8e3ff411e6c71a3cc19f0edb462d816",
     "grade": false,
     "grade_id": "calib-recap",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Recap: Extrinsic calibration\n",
    "\n",
    "The camera, LiDAR and radar data for a particular `Measurement` are recorded simultaneously.\n",
    "Still, we cannot plot the the camera, LiDAR and radar points in the same plot in a reasonable manner, because the sensors, and thereby the frame of reference for the point clouds, are at different locations.\n",
    "Thus, we need to take the measurement's frame of reference into account.\n",
    "\n",
    "The sensors are rigidly attached to the vehicle and the relative poses between the sensors do not change over time.\n",
    "The static transformations between the camera, LiDAR and radar were obtained using an extrinsic calibration procedure.\n",
    "Note that the transformations are given as 4x4 matrices for homogenous coordinates and points are given in `[x, y, z, 1]` homogeneous coordinates.\n",
    "\n",
    "We will be working with transformations between different sensors and transformations between different points in time.\n",
    "It is easy to lose track of which data is in what frame, so we start with establishing some conventions.\n",
    "\n",
    "\n",
    "## Recap: Transform naming conventions\n",
    "`pc_frameA`: point cloud (`pc`) given in frame `frameA` with shape (4, N) (homogeneous)\n",
    "\n",
    "`pc_frameB`: point cloud given in frame `frameB` with shape (4, N) (homogeneous)\n",
    "\n",
    "Convention: `T_frameB_frameA` with shape (4, 4) transforms `pc_frameA` into `frameB`: <br/>\n",
    "`pc_frameB = T_frameB_frameA.dot(pc_frameA)`\n",
    "\n",
    "You could also say, `frameA` gets cancelled out by `T_frameB_frameA`. This convention reads well if you apply multiple transformations:<br/>\n",
    "`T_frameC_frameA = T_frameC_frameB.dot(T_frameB_frameA)`\n",
    "\n",
    "Taking the inverse of the transformation matrix allows you to reverse the transformation:<br/>\n",
    "`T_frameB_frameA = np.linalg.inv(T_frameA_frameB)`\n",
    "\n",
    "See the code below for some hands-on transform juggling between the LiDAR and the radar frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1269b1fb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d9659ba19cb413b264e965491b449d7",
     "grade": false,
     "grade_id": "transformations",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.0e\n",
    "import numpy as np\n",
    "\n",
    "T_cam_lidar = measurements.get_T_camera_lidar()  # homogeneous transform\n",
    "T_cam_radar = measurements.get_T_camera_radar()\n",
    "T_lidar_cam = np.linalg.inv(T_cam_lidar)\n",
    "T_lidar_radar = np.dot(T_lidar_cam, T_cam_radar)\n",
    "T_radar_cam = np.linalg.inv(T_cam_radar)\n",
    "T_radar_lidar = np.dot(T_radar_cam, T_cam_lidar)\n",
    "T_radar_lidar  # homogeneneous transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58639df",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dffeedbbee310693a43a326a642ba493",
     "grade": false,
     "grade_id": "recap-homogeneous-transforms",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Recap on homogeneous transformation matrices\n",
    "See the code below for a recap on the content of a homogeneous transformation matrix and which computation of rotation and translation it combines within one operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9d3da7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba603128d77035f62d8b9d9dd638b3cf",
     "grade": false,
     "grade_id": "homogeneous-transforms-code",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.0f\n",
    "# rotation matrix is top left 3x3 sub-matrix of homogeneous matrix\n",
    "R_cam_lidar = T_cam_lidar[0:3, 0:3]\n",
    "# translation vector is rightmost column of homogeneous matrix\n",
    "# it reflects which point within the cam frame denotes the origin of the LiDAR frame.\n",
    "# this is also what you get, when you do T_cam_lidar.dot([0,0,0,1]) \n",
    "t_cam_lidar = T_cam_lidar[0:3, 3]\n",
    "\n",
    "# get random point in LiDAR frame (in homogeneous coordinates)\n",
    "p_lidar = np.random.random(4)\n",
    "p_lidar[3] = 1.0  # make homogeneous\n",
    "\n",
    "# transform LiDAR point to camera frame via homogeneous matrix\n",
    "p_cam1 = T_cam_lidar.dot(p_lidar)\n",
    "\n",
    "# transforma LiDAR point to camera frame 'manually' via rotation matrix and translation vector\n",
    "p_cam2 = R_cam_lidar.dot(p_lidar[:3]) + t_cam_lidar\n",
    "\n",
    "# both computation ways yield the same point in camera frame\n",
    "assert np.allclose(p_cam1[:3], p_cam2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55f08cc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c616c4af15d0402799a4b67b2dba4b63",
     "grade": false,
     "grade_id": "dataset-size",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.1 Dataset size\n",
    "Please work with the custom `Sequence` of `Dataset` with `start_index=1430` and `end_index=1545`. How many measurement timesteps does it consist of? Please set the variable `n_timesteps` to the corresponding size based on the `Sequence` object you instantiate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09c7eb3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bdb6f1c11e4c4f3c387bee46eb001946",
     "grade": false,
     "grade_id": "impl-dataset-size",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.1a\n",
    "from common.sequence_loader import Dataset\n",
    "\n",
    "start_index = 1430\n",
    "end_index = 1545\n",
    "\n",
    "n_timesteps = 0  # fill me with the right value\n",
    "sequence = None  # instantiate me from the Dataset\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "n_timesteps = end_index - start_index + 1\n",
    "sequence = dataset.get_custom_sequence(start_index, end_index)\n",
    "\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c575054",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b3811b88cf8276f680f1cc5d6ee402de",
     "grade": true,
     "grade_id": "impl-dataset-size-test",
     "locked": true,
     "points": 0.1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.1b\n",
    "# DO NOT DELETE THIS CELL!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07caadf6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f891454974dcbaef5e71c194e0c5c552",
     "grade": false,
     "grade_id": "plot-coordinate-frames-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.2 Coordinate frames\n",
    "Please use `k3d.plot` to create a 3D visualization with the coordinate axes of `camera`, `lidar` and `radar`.\n",
    "Goal is to see how the sensors are located relative to each other.\n",
    "Plot the three axes in the camera frame.\n",
    "\n",
    "Use `plot_axes` from `common.k3d_helpers` to visualize the coordinate axes.\n",
    "Use `k3d.text` to give the names `radar`, `camera` and `lidar` to the axes.\n",
    "For simplicity, we take the first measurements object of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29a952b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3f2f7a89fa461843482dd5e17956d24",
     "grade": false,
     "grade_id": "help-usage",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.2a\n",
    "from common.k3d_helpers import plot_axes\n",
    "\n",
    "# you can show the doc of the plot_axes function\n",
    "# via the builtin help() function\n",
    "#\n",
    "# or just put your cursor into the brackets of plot_axes()\n",
    "# and press shift-tab (multiple times)\n",
    "help(plot_axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c42e73c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a516f1417ae87245a0b2ddf89955c79e",
     "grade": false,
     "grade_id": "concepts-impl-plot-coordinate-frames",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.2b\n",
    "import k3d\n",
    "import numpy as np\n",
    "from common.k3d_helpers import plot_axes\n",
    "\n",
    "# use first measurement\n",
    "measurements = next(iter(sequence))\n",
    "\n",
    "# get transforms\n",
    "T_camera_lidar = measurements.get_T_camera_lidar()\n",
    "T_camera_radar = measurements.get_T_camera_radar()\n",
    "\n",
    "# create plot\n",
    "plot = k3d.plot(camera_auto_fit=False)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# For the plot of the camera coordinate axes I feed an identity matrix to the algorithm\n",
    "plot += plot_axes(T_plotorigin_target=np.eye(4).astype(np.float32), length=1.0)\n",
    "# For the plot of the lidar and radar coordinate axes I use the two transformation matrices already given\n",
    "plot += plot_axes(T_plotorigin_target=T_camera_lidar.astype(np.float32), length=1.0)\n",
    "plot += plot_axes(T_plotorigin_target=T_camera_radar.astype(np.float32), length=1.0)\n",
    "\n",
    "# For the labels, the camera frame will coincide with the origin so the label is easy to place\n",
    "plot += k3d.text('camera', position=[0, 0, 0], color=0xff0000, size=.5)\n",
    "# Regarding the lidar and radar, the position for the label can be taken from the last column of the homogeneous matrix\n",
    "lidar_label_pos = T_camera_lidar[:3,3]\n",
    "radar_label_pos = T_camera_radar[:3,3]\n",
    "plot += k3d.text('lidar', position=lidar_label_pos, color=0x00ff00, size=.5)\n",
    "plot += k3d.text('radar', position=radar_label_pos, color=0x0000ff, size=.5)\n",
    "\n",
    "# raise NotImplementedError()\n",
    "\n",
    "plot.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdb8a30",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4da10c7c41af03d2520be57ad25cea3a",
     "grade": true,
     "grade_id": "concepts-impl-plot-coordinate-frames-test",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.2c\n",
    "# DO NOT DELETE THIS CELL!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba7ab3d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "696546cafa2a75133b9f70d506fa2a69",
     "grade": false,
     "grade_id": "camera-conventions",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q 01.1 Camera axes conventions\n",
    "Within robotics, a usual convention of sensor frames is `x` pointing forward, `y` to the left and `z` to the top.\n",
    "We used these conventions for the LiDAR and the radar measurement frames.\n",
    "We also follow the typical convention for camera frames.\n",
    "\n",
    "In which directions do the axes `x`, `y` and `z` of the camera frame correspond to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66429595",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f4c9518fd8722876c53b23e422e6c579",
     "grade": false,
     "grade_id": "directions-options",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.2d\n",
    "pointing_directions_to_choose_from = {\n",
    "    \"viewing_direction\",\n",
    "    \"inverse_viewing_direction\",\n",
    "    \"left_of_image\",\n",
    "    \"right_of_image\",\n",
    "    \"top_of_image\",\n",
    "    \"bottom_of_image\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729f48a3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b897d501561e7611c6790a708d427362",
     "grade": false,
     "grade_id": "concepts-camera-axes",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.2e\n",
    "### A 01.1\n",
    "x_pointing_towards = None  # set to one of pointing_directions_to_choose_from\n",
    "y_pointing_towards = None  # set to one of pointing_directions_to_choose_from\n",
    "z_pointing_towards = None  # set to one of pointing_directions_to_choose_from\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "x_pointing_towards = \"right_of_image\"\n",
    "y_pointing_towards = \"bottom_of_image\"\n",
    "z_pointing_towards = \"viewing_direction\"\n",
    "\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64daf866",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de89cca0948857ead740c49bf4d2f0a8",
     "grade": true,
     "grade_id": "concepts-camera-axes-test",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.2f\n",
    "assert x_pointing_towards in pointing_directions_to_choose_from\n",
    "assert y_pointing_towards in pointing_directions_to_choose_from\n",
    "assert z_pointing_towards in pointing_directions_to_choose_from"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f6d1aa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "008c9c8076af8c92bbc687a60aba2300",
     "grade": false,
     "grade_id": "lidar-radar",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## 1.3 MP only - LiDAR point clouds and radar point clouds (3D)\n",
    "Use `k3d.plot` to draw the LiDAR points of the measurements within the sequence in blue and the radar target points in red (and larger).\n",
    "Also, draw the coordinate axes of both `lidar` and `radar` frame including text overlying their names.\n",
    "The `lidar` frame should be the origin of the plot.\n",
    "\n",
    "Draw the radial velocities of the radar sensor as `k3d.vectors` (cf. Practicum 3 MP).\n",
    "Please be reminded that `Measurements.get_radar_compensated_radial_velocities()` represents the radial velocities in the `radar` frame and the plot is represented in the `lidar` frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47387d42",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "489221f01162ce24faa4f3c4eda88b0e",
     "grade": false,
     "grade_id": "concepts-impl-plot-lidar-radar-point-clouds",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.3a\n",
    "import k3d\n",
    "if COURSE_TYPE == 'MP' or RUN_ALL:\n",
    "    # get first measurement of sequence\n",
    "    measurements = next(iter(sequence))\n",
    "\n",
    "    plot = k3d.plot(camera_auto_fit=True)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # This code will be mostly taken from Practicum 3\n",
    "    \n",
    "    # First we get the lidar radar points\n",
    "    p_lidar = measurements.get_lidar_points()[:, 0:3]\n",
    "    # Then we need to get the radar points in the lidar frame\n",
    "    p_radar = measurements.get_radar_points()\n",
    "    p_radar_lf = T_lidar_radar.dot(p_radar.T).T[:, 0:3]\n",
    "    # Then we add them to the plot\n",
    "    plot += k3d.points(positions=p_lidar, point_size=0.03, color=0x0000ff)\n",
    "    plot += k3d.points(positions=p_radar_lf, point_size=0.3, color=0xff0000)\n",
    "    \n",
    "    # We add the coordinate axes for the lidar frame with its label\n",
    "    plot += plot_axes(T_plotorigin_target = np.eye(4).astype(np.float32), length=1.0)\n",
    "    plot += k3d.text('lidar', position = [0, 0, 0], color = 0x00ff00, size=.5)\n",
    "    # And we do the same for the radar\n",
    "    plot += plot_axes(T_plotorigin_target = T_lidar_radar.astype(np.float32), length = 1.0)\n",
    "    radar_label_pos = T_lidar_radar[:3,3]\n",
    "    plot += k3d.text('radar', position = radar_label_pos, color = 0x0000ff, size=.5)\n",
    "    \n",
    "    # Now we want to add the radial velocities of the radar sensor\n",
    "    # First we get the measurements in the radar frame from the data\n",
    "    compensated_radial_velocity =  measurements.get_radar_compensated_radial_velocities().astype(np.float32)\n",
    "    # Then we calculate the unit vectors and multiply them by the respective radial velocity\n",
    "    # Notice that the unit vector is calculated with the points in the radar frame since that is the only radial velocity value we have\n",
    "    unit_vectors = np.zeros((p_radar.shape[0], 3))\n",
    "    velocity_vectors = np.zeros((p_radar.shape[0], 3))\n",
    "    for i in range(p_radar.shape[0]):\n",
    "        unit_vectors[i, :] = [p_radar[i, 0] / np.sqrt(p_radar[i, 0]**2 + p_radar[i, 1]**2 + p_radar[i, 2]**2),\n",
    "                              p_radar[i, 1] / np.sqrt(p_radar[i, 0]**2 + p_radar[i, 1]**2 + p_radar[i, 2]**2),\n",
    "                              p_radar[i, 2] / np.sqrt(p_radar[i, 0]**2 + p_radar[i, 1]**2 + p_radar[i, 2]**2)] \n",
    "        velocity_vectors[i, :] = unit_vectors[i, :] * compensated_radial_velocity[i]\n",
    "    # Finally we add the vectors to the plot starting from the radar points in the lidar frame\n",
    "    plot += k3d.vectors(origins=p_radar_lf.astype(np.float32), vectors=velocity_vectors.astype(np.float32), color=0xff0000)\n",
    "    \n",
    "#     raise NotImplementedError()\n",
    "    plot.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989d867a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eee962e31d8499124e042ed566ffa330",
     "grade": true,
     "grade_id": "mp-only-concepts-impl-plot-lidar-radar-point-clouds-test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.3b\n",
    "if COURSE_TYPE == 'MP' or RUN_ALL:\n",
    "    point_clouds = [o.positions for o in plot.objects if o.type == \"Points\"]\n",
    "    assert len(point_clouds) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c302f0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b45a4daef1f7e4cdb4a63ead0fefd4e8",
     "grade": false,
     "grade_id": "mp-only-lidar-point-clouds-in-camera-image",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.4 MP only - LiDAR point clouds in the camera image\n",
    "Now, project the LiDAR point cloud into the camera image of the first frame of the sequence using the `project_points` function you implemented in Practicum 1.\n",
    "Use `cv2.circle` to draw **filled circles in red** `(0, 0, 255)`, `radius=3` and `thickness=-1`, so we can check the output.\n",
    "Make sure you only draw visible points into the camera image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c4ec2e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17aca3d448cd33776713ba280cd0e9ce",
     "grade": false,
     "grade_id": "impl-plot-lidar-in-camera-image",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.4a\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from common.visualization import showimage\n",
    "from ipynb.fs.defs.practicum1 import project_points\n",
    "if COURSE_TYPE == 'MP' or RUN_ALL:\n",
    "    image_draw = np.zeros((1216, 1936, 3))  # overwrite me\n",
    "    color_red = (0, 0, 255)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Get the measurements from the first frame\n",
    "    measurements = sequence[start_index]\n",
    "    \n",
    "    # I get the camera image and projection matrix from the data from the data\n",
    "    image_draw = measurements.get_camera_image()\n",
    "    projection_matrix = measurements.get_camera_projection_matrix()\n",
    "    \n",
    "    # I also get the lidar points and ransform them in the camera frame\n",
    "    p_lidar = measurements.get_lidar_points()\n",
    "    p_lidar_cf = T_camera_lidar.dot(p_lidar.T).T\n",
    "    \n",
    "    # I now project the points in the camera image\n",
    "    uvs = project_points(projection_matrix, p_lidar_cf)\n",
    "    # I reduce the array to only include the lidar points visible in the camera image\n",
    "    uvs_reduced = uvs[uvs[:, 0] >= 0]\n",
    "    uvs_reduced = uvs_reduced[uvs_reduced[:, 0] < image_draw.shape[1]]\n",
    "    uvs_reduced = uvs_reduced[uvs_reduced[:, 1] >= 0]\n",
    "    uvs_reduced = uvs_reduced[uvs_reduced[:, 1] < image_draw.shape[0]]\n",
    "    \n",
    "    # Finally, I draw the circles in the image\n",
    "    for uv in uvs_reduced:\n",
    "         cv2.circle(image_draw, tuple(uv.astype(int)), 3, color_red, -1)\n",
    "    \n",
    "#     raise NotImplementedError()\n",
    "\n",
    "    showimage(image_draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed83248",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8674047426959f48287ab2818c919b60",
     "grade": true,
     "grade_id": "mp-only-impl-plot-lidar-in-camera-image-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.4b\n",
    "if COURSE_TYPE == 'MP' or RUN_ALL:\n",
    "    color_red = (0, 0, 255)\n",
    "    assert image_draw.shape == (1216, 1936, 3)\n",
    "    assert np.all(image_draw[806, 7] == color_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e39972",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed1754e1bce78e9036cc984c97d79da8",
     "grade": false,
     "grade_id": "question-uv-direction",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Projected coordinates are conventionally denoted by `u` and `v`.\n",
    "\n",
    "1. Which camera frame axes do they correspond to?\n",
    "2. In which direction does a point with increasing `u` wander?\n",
    "3. In which direction doeas a point with increasing `v` wander?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254bd602",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a07a2f254c4a94f10e2549ac2d753974",
     "grade": false,
     "grade_id": "concepts-uv-direction",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.4c\n",
    "if COURSE_TYPE == 'MP' or RUN_ALL:\n",
    "    axis_corresponding_to_u = None  # choose from \"x\", \"y\", \"z\"\n",
    "    axis_corresponding_to_v = None  # choose from \"x\", \"y\", \"z\"\n",
    "    direction_wandering_with_increasing_u = None  # choose from \"up\", \"down\", \"left\", \"right\"\n",
    "    direction_wandering_with_increasing_v = None  # choose from \"up\", \"down\", \"left\", \"right\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    axis_corresponding_to_u = \"x\"  # choose from \"x\", \"y\", \"z\"\n",
    "    axis_corresponding_to_v = \"y\"  # choose from \"x\", \"y\", \"z\"\n",
    "    direction_wandering_with_increasing_u = \"right\"  # choose from \"up\", \"down\", \"left\", \"right\"\n",
    "    direction_wandering_with_increasing_v = \"down\"  # choose from \"up\", \"down\", \"left\", \"right\"\n",
    "    \n",
    "#     raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6facf5c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e9daa60be939f03143407e01368e863",
     "grade": true,
     "grade_id": "mp-only-concepts-uv-direction-test",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.4d\n",
    "if COURSE_TYPE == 'MP' or RUN_ALL:\n",
    "    assert axis_corresponding_to_u in {\"x\", \"y\", \"z\"}\n",
    "    assert axis_corresponding_to_v in {\"x\", \"y\", \"z\"}\n",
    "    assert direction_wandering_with_increasing_u in {\"up\", \"down\", \"left\", \"right\"}\n",
    "    assert direction_wandering_with_increasing_v in {\"up\", \"down\", \"left\", \"right\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a529be",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d747d0cfbe701efcb45684211e71b838",
     "grade": false,
     "grade_id": "cell-529f2491a1717521",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "How many LiDAR points are being projected **onto** the image?\n",
    "Please fill `n_lidar_points_within_camera_image` below with the proper value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fed5a20",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e738116d069dce005c5cc162e7fe7108",
     "grade": false,
     "grade_id": "impl-n-lidar-points-in-image",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.4e\n",
    "if COURSE_TYPE == 'MP' or RUN_ALL:\n",
    "    n_lidar_points_within_camera_image = 0  # replace me\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    n_lidar_points_within_camera_image = uvs_reduced.shape[0]\n",
    "    \n",
    "#     raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5741253c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "04ad982624aa378b9d4e5152ec3377b1",
     "grade": true,
     "grade_id": "mp-only-impl-n-lidar-points-in-image-test",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.4f\n",
    "if COURSE_TYPE == 'MP' or RUN_ALL:\n",
    "    # if below assertion fails, please make sure that your project_points implementation actually\n",
    "    # uses rounded values\n",
    "    assert n_lidar_points_within_camera_image == 20382, n_lidar_points_within_camera_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582759a1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32834b28013865a62c197bca7c5dc8ab",
     "grade": false,
     "grade_id": "cell-529f2491a1717522",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.5 MP only - Radar measurements in the camera image (video)\n",
    "Now, create a video which displays the radar measurement point cloud of each frame of the sequence as circles over the camera image.\n",
    "Please draw **filled circles in yellow** `(0, 255, 255)`, `radius=20` and `thickness=-1`, so we can check the output.\n",
    "You don't have to draw radial velocities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33268637",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35bd9e7ab90e3648847abaf445917bab",
     "grade": false,
     "grade_id": "impl-plot-radar-in-image",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.5a\n",
    "from common.visualization import create_animation\n",
    "from IPython.core.display import HTML\n",
    "from tqdm.notebook import tqdm\n",
    "video = None\n",
    "if COURSE_TYPE == 'MP' or RUN_ALL:\n",
    "    color_yellow = (0, 255, 255)\n",
    "    radius = 20\n",
    "    images_draw = []  # append images here\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # We iterate over all the time instants in the sequence\n",
    "    for measurements in sequence:\n",
    "        # First we get the image and the projection matrix for the single frame\n",
    "        image_draw = measurements.get_camera_image()\n",
    "        projection_matrix = measurements.get_camera_projection_matrix()\n",
    "        # Now we do the same procedure as before only with radar points instead of lidar for the single frame\n",
    "        p_radar = measurements.get_radar_points()\n",
    "        p_radar_cf = T_camera_radar.dot(p_radar.T).T\n",
    "        uvs = project_points(projection_matrix, p_radar_cf)\n",
    "        uvs_reduced = uvs[uvs[:, 0] >= 0]\n",
    "        uvs_reduced = uvs_reduced[uvs_reduced[:, 0] < image_draw.shape[1]]\n",
    "        uvs_reduced = uvs_reduced[uvs_reduced[:, 1] >= 0]\n",
    "        uvs_reduced = uvs_reduced[uvs_reduced[:, 1] < image_draw.shape[0]]\n",
    "        # Now we draw the radar points in the single frame\n",
    "        for uv in uvs_reduced:\n",
    "            cv2.circle(image_draw, tuple(uv.astype(int)), radius, color_yellow, -1)\n",
    "        # Finally we append the modified frame to the list for the animation\n",
    "        images_draw.append(image_draw)\n",
    "\n",
    "#     raise NotImplementedError()\n",
    "\n",
    "    # we use create_animation to show the video inline\n",
    "    # and yes: it takes some time\n",
    "    anim = create_animation(images_draw)\n",
    "    video = anim.to_html5_video()\n",
    "HTML(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271fef07",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fd85b6d40d74ee562395235c3105b6a2",
     "grade": true,
     "grade_id": "mp-only-impl-plot-radar-in-image-test",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.5b\n",
    "if COURSE_TYPE == 'MP' or RUN_ALL:\n",
    "    assert len(images_draw) == 116, len(images_draw)\n",
    "    assert anim.save_count == 116, len(anim.save_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef3fc67",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5a24b6da5bb5463456b3a524c57029ea",
     "grade": false,
     "grade_id": "cell-529f2491a1717523",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.6 IV only - Vehicle pose over time\n",
    "The dataset also offers the vehicle pose for each frame with respect to a world static frame. The function `measurements.get_T_world_radar()` gives the transformation of the vehicle-mounted radar frame to a world static point (think: origin of `world` is the pose of the radar frame when ignition was turned on, so the car might have traveled a couple of kilometers from there).\n",
    "\n",
    "Your next task is to create a `k3d` plot which denotes the radar frame locations over the sequence.\n",
    "Please introduce a frame `radar0` which represents the pose of the radar frame at the beginning of the sequence.\n",
    "This frame should be the origin of the plot, denoted by a larger axes (see the `length` parameter of `plot_axes`).\n",
    "\n",
    "Now create the 3D plot showing the trajectory of the radar frame with respect to `radar0`.\n",
    "Make sure you draw exactly one axes per timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a3091f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba9c22ebe09dadd5205f2c9e7dfa385a",
     "grade": false,
     "grade_id": "concepts-impl-plot-vehicle-pose",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.6a\n",
    "from common.k3d_helpers import plot_axes\n",
    "if COURSE_TYPE == 'IV' or RUN_ALL:\n",
    "    dataset = Dataset()\n",
    "    sequence = dataset.get_custom_sequence(start_index, end_index)\n",
    "\n",
    "    plot = k3d.plot(camera_auto_fit=False)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    plot.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bfbb32",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ba1082447ee71d7ea0ae95dab3d58d6",
     "grade": true,
     "grade_id": "iv-only-concepts-impl-plot-vehicle-pose-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.6b\n",
    "if COURSE_TYPE == 'IV' or RUN_ALL:\n",
    "    axes_objects = [o for o in plot.objects if o.type == \"Vectors\"]\n",
    "    assert len(axes_objects) in {\n",
    "        n_timesteps,\n",
    "        n_timesteps + 1,  # start might be drawn as small and large axes over each other\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35c5dea",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe875e484647060a7c3d90e8d3ff98ee",
     "grade": false,
     "grade_id": "distance-travelled-questions",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**IV only**\n",
    "\n",
    "How many meters has the car travelled from start to the end of the sequence?\n",
    "Approximate with intermediate trajectory points.\n",
    "Consider movement along x, y, and z.\n",
    "\n",
    "Please set the value of `distance_travelled_m` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5350d2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1d53a5ac4efa59ce092a34c2de99794",
     "grade": false,
     "grade_id": "impl-distance-travelled",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.6c\n",
    "if COURSE_TYPE == 'IV' or RUN_ALL:\n",
    "    distance_travelled_m = 0.0  # replace me with the proper distance\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    print(distance_travelled_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ef779d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "daae0703808e0e140fa47fb6276bdea8",
     "grade": true,
     "grade_id": "iv-only-impl-distance-travelled-test",
     "locked": true,
     "points": 0.6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.6d\n",
    "if COURSE_TYPE == 'IV' or RUN_ALL:\n",
    "    # DO NOT DELETE THIS CELL!\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3535eb43",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "63ba8e4aa7a75f808f80852ad7638f68",
     "grade": false,
     "grade_id": "annotated-objects",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.7 Annotated objects\n",
    "The dataset comes with manually annotated objects, which we also call (ground truth) labels.\n",
    "It includes the object class, its transformation with the camera frame `T_cam_object` and its extent in object frame (length, width, height):\n",
    "* length: along object x axis\n",
    "* width: along object y axis\n",
    "* height: along object z axis\n",
    "\n",
    "The origin of the object is at the bottom center (see `get_corners_object` in practicum 1).\n",
    "\n",
    "Let's have a look at an example annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea25f6db",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32b3bde177f6b18bfb7dff32a10df736",
     "grade": false,
     "grade_id": "labels-camera-loading",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.7a\n",
    "from common.k3d_helpers import plot_box\n",
    "\n",
    "dataset = Dataset()\n",
    "sequence = dataset.get_custom_sequence(start_index, end_index)\n",
    "measurements = next(iter(sequence))\n",
    "labels_camera = measurements.get_labels_camera()\n",
    "len(labels_camera), labels_camera[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75dd777",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f3512d47830359fe0f7be5217a5d2b2",
     "grade": true,
     "grade_id": "annotated-objects-intro-test",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.7b\n",
    "import numpy as np\n",
    "\n",
    "# Let's make sure the implementation of get_T_cam_object() does the right thing\n",
    "# Otherwise you need to fix your implementation of get_T_cam_object() within practicum 1\n",
    "# get_T_cam_object() from practicum 1 is being called in get_labels_camera()\n",
    "assert np.allclose(\n",
    "    labels_camera[1][\"T_cam_object\"],\n",
    "    np.array(\n",
    "        [\n",
    "            [-0.7481051, -0.66340834, 0.0151049, 7.933778],\n",
    "            [0.06748124, -0.09870181, -0.9928264, 3.0391772],\n",
    "            [0.66014016, -0.7417193, 0.1186069, 14.156578],\n",
    "            [0.0, 0.0, 0.0, 1.0],\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4eeb38",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "44a7322004873b1d8e50bb1c7f4d30cc",
     "grade": false,
     "grade_id": "plot-annotated-objects",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As you can see, the first frame of the sequence has 13 annotation, and the label with index 1 is a Pedestrian with a height of about 1.69m (`labels_camera[1][\"extent_object\"][2]`).\n",
    "\n",
    "### Plot annotated objects\n",
    "\n",
    "We created a helper function for you which adds a 3D representation of a label to a `k3d` plot. The function `plot_box(plot, label_camera, T_target_camera)` takes the information from the `label_camera` dict, and uses the transform `T_target_camera` to transform the labels originally given in the `camera` frame to the `target` frame.\n",
    "`target` frame corresponds to the origin of the plot.\n",
    "\n",
    "Now, please create a `k3d.plot` and visualize all the labels of the first frame within the sequence in the `lidar` frame.\n",
    "We also plot the axes of the `lidar` frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b442f850",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a4771362501b2803d8bc3eeba91439ba",
     "grade": false,
     "grade_id": "impl-plot-annotated-objects",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.7c\n",
    "plot = k3d.plot()\n",
    "plot += plot_axes(np.eye(4, dtype=np.float32))  # this should represent the LiDAR frame\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "for i in range(len(labels_camera)):\n",
    "    plot_box(plot, labels_camera[i], T_lidar_cam)    \n",
    "\n",
    "# raise NotImplementedError()\n",
    "\n",
    "plot.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136a1ff0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2a27e15a067dee2ccad5236f006fd2e",
     "grade": true,
     "grade_id": "impl-plot-annotated-objects-test",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.7d\n",
    "axes_objects = [o for o in plot.objects if o.type == \"Vectors\"]\n",
    "assert len(axes_objects) == 13 + 1, len(axes_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6031c031",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ba4fa1be189d0eb1ae5019bbd8cdd06a",
     "grade": false,
     "grade_id": "colors-of-object-classes",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Colors of object classes\n",
    "Which class do the different colors of the bounding boxes represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf4bead",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7595b345bc4afda4e2b1f2035297e8d6",
     "grade": false,
     "grade_id": "concepts-bbox-colors",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.7e\n",
    "available_colors = {\"red\", \"blue\", \"green\", \"yellow\", \"gray\", \"magenta\", \"orange\"}\n",
    "available_classes = {\"Car\", \"Cyclist\", \"DontCare\", \"Pedestrian\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fcfbcb",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3adb69d520ca7e82433100b4b23c1c18",
     "grade": false,
     "grade_id": "cell-e01585711bbe4150",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.7f\n",
    "\n",
    "# set the dictionary to map from available colors to available classes\n",
    "# make sure you only use colors which are actually present in the visualization\n",
    "# make sure to only use classes which are actually present in the visualization\n",
    "color_represents = {\n",
    "    \"red\": None,  # set me to proper class\n",
    "    # extend me with other color to class mappings\n",
    "}\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "color_represents = {\n",
    "    \"red\": \"Car\",\n",
    "    \"blue\": \"Cyclist\",\n",
    "    \"green\": \"Pedestrian\",\n",
    "    \"gray\": \"DontCare\"\n",
    "}\n",
    "\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0da049",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08d3e125d8ccd26a35f73c64de8ddb75",
     "grade": true,
     "grade_id": "concepts-bbox-colors-test",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.7g\n",
    "assert set(color_represents.keys()).issubset(available_colors)\n",
    "assert set(color_represents.values()).issubset(available_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d9368",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cf306af449bb682f0a8114d398faa1ff",
     "grade": false,
     "grade_id": "get-corners-object",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The function `get_corners_object` gets the 8 corner points of a label dictionary as homogeneous points within the object frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf8b79f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2f5b49129fe84ac1e0fac31400f1067",
     "grade": false,
     "grade_id": "corners-object",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.7h\n",
    "from ipynb.fs.defs.practicum1 import get_corners_object\n",
    "\n",
    "label_camera = labels_camera[1]\n",
    "corners_object = get_corners_object(label_camera[\"extent_object\"])\n",
    "corners_object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b3dc79",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "83c8389139f06f33c19a0385598be385",
     "grade": false,
     "grade_id": "project-object-corners",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Project object corners\n",
    "Now, your task is to draw the projection of those 8 points of `label_camera` as *filled* circles (radius >= 3) into the camera image.\n",
    "You can choose any color, as long its distinguishable from the image content.\n",
    "All points need to be of the same color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d229612",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "554ed1c741c80fc1acaac40810a9e31e",
     "grade": false,
     "grade_id": "impl-plot-label-corners",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.7i\n",
    "image_draw = measurements.get_camera_image()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "projection_matrix = measurements.get_camera_projection_matrix()\n",
    "\n",
    "for i in range(len(labels_camera)):\n",
    "    label_camera = labels_camera[i]\n",
    "    corners_object = get_corners_object(label_camera[\"extent_object\"])\n",
    "#     print(corners_object)\n",
    "    \n",
    "    T_cam_object = label_camera[\"T_cam_object\"]\n",
    "    corners_object_cf = T_cam_object.dot(corners_object.T).T\n",
    "#     print(object_position)\n",
    "    \n",
    "#     corners_object_cf = T_camera_lidar.dot((corners_object + object_position).T).T\n",
    "#     print(corners_object + object_position)\n",
    "    \n",
    "    uvs = project_points(projection_matrix, corners_object_cf)\n",
    "#     print(uvs)\n",
    "    \n",
    "    for uv in uvs:\n",
    "        cv2.circle(image_draw, tuple(uv.astype(int)), 5, (0, 255, 0), -1)\n",
    "\n",
    "# raise NotImplementedError()\n",
    "showimage(image_draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5618659",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c2e9c4cb3a4c3f91666fe530cc21051",
     "grade": true,
     "grade_id": "impl-plot-label-corners-test",
     "locked": true,
     "points": 0.3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.7j\n",
    "# DO NOT DELETE THIS CELL!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864cb018",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd5d7a0da6db711b2825574412d5e8d9",
     "grade": false,
     "grade_id": "bounding-box",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.8 Bounding Box\n",
    "Now, create a function which creates a `BoundingBox` object (see Practicum 1) from the `objects_dict` (`label_camera`).\n",
    "We use the helper function `draw_bbox_to_image` to draw the `BoundingBox` object to the image `image_draw`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ef3813",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da72eea31ab95a8c638e54d8405dbdde",
     "grade": false,
     "grade_id": "impl-bbox-from-object",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.8a\n",
    "from common.visualization import draw_bbox_to_image\n",
    "from practicum1.BoundingBox import BoundingBox\n",
    "\n",
    "print(label_camera[\"2d_bbox\"])\n",
    "\n",
    "def get_bounding_box_from_object(object_dict, projection_matrix):\n",
    "\n",
    "    bbox = BoundingBox(1, 2, 3, 4)  # set me to the right values\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Get the object dimension and position from the dictionary\n",
    "    extent_object = object_dict[\"extent_object\"]\n",
    "    T_cam_object = object_dict[\"T_cam_object\"]\n",
    "    \n",
    "    # Rotate the dimension to be compliant to the camera frame\n",
    "    R_cam_object = T_cam_object[0:3, 0:3]\n",
    "    extent_object_cf = R_cam_object.dot(extent_object)\n",
    "    \n",
    "    # Calculate the corners of the box in the 3D space\n",
    "    corners = []\n",
    "    corners.append([T_cam_object[0, 3] - extent_object_cf[0]/2, T_cam_object[1, 3],                       T_cam_object[2, 3]])\n",
    "    corners.append([T_cam_object[0, 3] + extent_object_cf[0]/2, T_cam_object[1, 3],                       T_cam_object[2, 3]])\n",
    "    corners.append([T_cam_object[0, 3] - extent_object_cf[0]/2, T_cam_object[1, 3] + extent_object_cf[1], T_cam_object[2, 3]])\n",
    "    corners.append([T_cam_object[0, 3] + extent_object_cf[0]/2, T_cam_object[1, 3] + extent_object_cf[1], T_cam_object[2, 3]])\n",
    "    corners = np.array(corners)\n",
    "\n",
    "    # Project the points in 2D space\n",
    "    corners_aug = np.hstack((corners, np.ones((corners.shape[0], 1))))\n",
    "    corners_2d = project_points(projection_matrix, corners_aug)\n",
    "\n",
    "    # Create the bounding boxes from the corners\n",
    "    if corners_2d[1, 0] < corners_2d[2, 0]:\n",
    "        bbox = BoundingBox(corners_2d[2, 1].astype(np.int32), corners_2d[1, 0].astype(np.int32), corners_2d[1, 1].astype(np.int32), corners_2d[2, 0].astype(np.int32), from_corners=True)\n",
    "    else:\n",
    "        bbox = BoundingBox(corners_2d[2, 1].astype(np.int32), corners_2d[2, 0].astype(np.int32), corners_2d[1, 1].astype(np.int32), corners_2d[1, 0].astype(np.int32), from_corners=True)\n",
    "    \n",
    "#     raise NotImplementedError()\n",
    "    assert isinstance(bbox, BoundingBox)\n",
    "    return bbox\n",
    "\n",
    "# Here it made more sense to me to print all the bounding boxes in the image, therefore I added an iteration for all the objects\n",
    "for label_camera in labels_camera:\n",
    "    bbox = get_bounding_box_from_object(label_camera, measurements.get_camera_projection_matrix())\n",
    "    draw_bbox_to_image(image_draw, bbox, thickness=1)\n",
    "showimage(image_draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086cd13a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9ac8fe9934d4db15a395cdc4b5639ce",
     "grade": true,
     "grade_id": "impl-bbox-from-object-test",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.8b\n",
    "# DO NOT REMOVE THIS CELL!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6572628b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40a980659de24b78d63f31141d624edb",
     "grade": false,
     "grade_id": "ground-plane-visualization",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.9 Ground plane visualization\n",
    "The road surface in front of the vehicle can be represented as a flat ground plane.\n",
    "A representation of a plane is `[a, b, c, d]` and the plane is defined by all points `[x, y, z]` which suffice the equation $ax + by + cz + d = 0$\n",
    "\n",
    "E.g., for the first frame of the sequence, the plane coefficients in `lidar` frame are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9adebb2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ced7e549ea7abb16cfff462d690b8c19",
     "grade": false,
     "grade_id": "ground-plane-visualization-plane",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.9a\n",
    "plane_lidar = np.array([0.00312662, 0.0069831, 0.99997073, 1.58132066])\n",
    "plane_lidar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80db04c7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "17ec58ce44121f2d5a156a9a6408d20a",
     "grade": false,
     "grade_id": "meshgrid",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can *sample* points on the plane by fixing an x and y value and calculating the corresponding z value (or any other combination).\n",
    "\n",
    "### Meshgrid\n",
    "Now, find the Z points which reside on the plane on a rectangular grid of x and y values (`x_min`..`x_max`, `y_min`..`y_max`) with distance of `x_step = y_step = 0.5`m.\n",
    "See `np.linspace`/`np.arange` and `np.meshgrid`.\n",
    "The maxima are defined inclusive, e.g., along the x-axis there should be 41 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fb23b8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d93c10a91b50d0d397e8de450e71be5",
     "grade": false,
     "grade_id": "impl-plane-visualization",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.9b\n",
    "# do not change these\n",
    "x_min = 2\n",
    "x_max = 22\n",
    "y_min = -10\n",
    "y_max = 10\n",
    "x_step = 0.5\n",
    "y_step = 0.5\n",
    "\n",
    "\n",
    "def get_plane_meshgrid(plane_model, x_min, x_max, y_min, y_max, x_step, y_step):\n",
    "    a, b, c, d = plane_model\n",
    "\n",
    "    # number of elements in x and y direction\n",
    "    n_x = int((x_max - x_min) / x_step) + 1  # +1 to account for x_max being inclusive\n",
    "    n_y = int((y_max - y_min) / y_step) + 1  # +1 to account for y_max being inclusive\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # I first define all the values for x and y\n",
    "    x = np.arange(x_min, x_max + x_step, x_step)\n",
    "    y = np.arange(y_min, y_max + y_step, y_step)\n",
    "    # Then I create the meshgrid with those values\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    # Finally I calculate the value of Z using the plane equation\n",
    "    Z = (a * X + b * Y + d) / (- c)\n",
    "    \n",
    "#     raise NotImplementedError()\n",
    "\n",
    "    assert X.shape == (n_y, n_x)\n",
    "    assert Y.shape == (n_y, n_x)\n",
    "    assert Z.shape == (n_y, n_x)\n",
    "\n",
    "    return X, Y, Z\n",
    "\n",
    "\n",
    "Xs_lidar, Ys_lidar, Zs_lidar = get_plane_meshgrid(plane_lidar, x_min, x_max, y_min, y_max, x_step, y_step)\n",
    "# let's stack the values so we have XYZ values of all points on the mesh\n",
    "XYZs_lidar = np.vstack([Xs_lidar.ravel(), Ys_lidar.ravel(), Zs_lidar.ravel()]).T\n",
    "XYZs_lidar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a6f762",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34029a8dc91e4e4fcc108e19f58eb0b7",
     "grade": true,
     "grade_id": "impl-mesh-test",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.9c\n",
    "assert XYZs_lidar.shape == (1681, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca52882",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0006ea5122cdbb4d05efc0311217d72c",
     "grade": false,
     "grade_id": "3d-mesh-plot",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3D mesh plot\n",
    "Now, plot the sampled `XYZs` points on the grid with `k3d.points` within the LiDAR frame as red dots. \n",
    "Please draw a `k3d.mesh` of the plane.\n",
    "You can feed `k3d.mesh` with `XYZs` after applying a Delaunay triangulation from `matplotlib.tri.Triangulation`.\n",
    "See also [K3D-jupyter mesh example](https://k3d-jupyter.org/basic_functionality/Mesh.html).\n",
    "Setting `attribute` and/or `opacity` might come in handy.\n",
    "\n",
    "**MP only**:\n",
    "Please also plot the LiDAR points of `start_index` alongside, so you can visually verify that you've been implementing the right thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014cf877",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23015b7860601e22bf0c5d121cd6c4e5",
     "grade": false,
     "grade_id": "plot-plane-visualization-solution",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.9d\n",
    "plot = k3d.plot()\n",
    "plot += plot_axes(np.eye(4, dtype=np.float32))  # LiDAR frame\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# First I plot the sampled XYZs points\n",
    "plot += k3d.points(positions=XYZs_lidar.astype(np.float32), point_size=0.1, color=0xff0000)\n",
    "\n",
    "# Then I import the triangulation function\n",
    "from matplotlib.tri import Triangulation\n",
    "# Then I get the triangle vertices by triangulating the flattened arrays\n",
    "indices = Triangulation(Xs_lidar.flatten(), Ys_lidar.flatten()).triangles.astype(np.uint32)\n",
    "# Finally I plot the mesh\n",
    "plt_mesh = k3d.mesh(XYZs_lidar.astype(np.float32), indices, attribute=Zs_lidar)\n",
    "plot += plt_mesh\n",
    "\n",
    "# Finally I plot the lidar points\n",
    "measurements = sequence[start_index]\n",
    "p_lidar = measurements.get_lidar_points()\n",
    "plot += k3d.points(positions=p_lidar[:, 0:3].astype(np.float32), point_size=0.03, color=0x0000ff)\n",
    "\n",
    "# raise NotImplementedError()\n",
    "\n",
    "plot.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c721b6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "773d4845f418cb1de58a5cffb17e9b86",
     "grade": true,
     "grade_id": "impl-plane-visualization-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.9e\n",
    "points_objects = [o for o in plot.objects if o.type == \"Points\"]\n",
    "if COURSE_TYPE == 'MP' or RUN_ALL:\n",
    "    assert len(points_objects) == 2  # LiDAR and grid\n",
    "elif COURSE_TYPE == 'IV':\n",
    "    assert len(points_objects) in {1, 2}  # at least grid, LiDAR optional\n",
    "  \n",
    "mesh_objects = [o for o in plot.objects if o.type == \"Mesh\"]\n",
    "assert len(mesh_objects) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad251d0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "67623b83b69cde16d6929169fb532b38",
     "grade": false,
     "grade_id": "precomputed-ground-planes-and-trajectory",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.10 Precomputed ground planes and trajectory in world static frame\n",
    "We provide you **precomputed ground planes** in the camera frame and with the **trajectory** of the camera frame within a world static frame.\n",
    "\n",
    "### Ground planes\n",
    "You can obtain precomputed ground planes given in the camera frame via `Measurements.get_ground_plane()`.\n",
    "It follows the `[a, b, c, d]` convention mentioned in the previous notebook (but is given in the **camera frame**).\n",
    "\n",
    "### Trajectory\n",
    "`T_newworld_camera` (via `Measurements.get_T_newworld_camera()`) represents the pose of the camera over time for the world-static frame `newworld`.\n",
    "`newworld` has its origin at the pose of the radar sensor during frame `1430`, i.e. at frame `1430`, the `T_newworld_cam` corresponds to `T_radar_cam`.\n",
    "We called it *`newworld`* to differentiate from the `world` frame in `Measurements.get_T_world_radar()`.\n",
    "\n",
    "### Your Task\n",
    "#### Plot camera axes in `newworld`\n",
    "Use a `k3d.plot` to visualize the trajectory of the `camera` frame within the `newworld` frame as axes (`plot_axes()`) for every 10th frame within the sequence.\n",
    "The getter is `Measurements.get_T_newworld_camera()`\n",
    "Also plot the axes of the `newworld` frame.\n",
    "Use `k3d.text` to name the frame `newworld`, and the index (1430, 1440, ...) for the trajectoy axes.\n",
    "\n",
    "#### Plot precomputed ground planes\n",
    "In addition, please plot the ground plane of each 10th frame as a mesh in the `newworld` frame.\n",
    "Use distinct colors, like `from common.visualization import colors_qualitative_k3d`.\n",
    "Consider, that the ground plane model is given in **camera frame** for each frame, so sample y values for a grid of x and z values ([`x_min`..`x_max`] and [`z_min`..`z_max`]), as `y` values of the plane (within the camera frame) are nearly constant within the camera frame.\n",
    "Or use `transform_plane()` below and sample in `lidar` frame in `x` and `y` as we did above.\n",
    "\n",
    "#### Example output\n",
    "The resulting k3d plot should look similar to this:\n",
    "![Example k3d plot](fa_01a_ground_plane_trajectories.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d788a0e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "abf9780a4cd6e1fec4fb831a1d3baa81",
     "grade": true,
     "grade_id": "impl-precomputed-ground-planes-and-trajectory",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.10a\n",
    "import k3d\n",
    "from common.sequence_loader import Dataset\n",
    "from common.visualization import colors_qualitative_k3d\n",
    "from common.k3d_helpers import plot_axes\n",
    "\n",
    "# you might find the below function handy to transform plane coefficients between different frames.\n",
    "# E.g., when you want to reuse get_plane_meshgrid\n",
    "# which samples along x and y dimension e.g., in LiDAR frame,\n",
    "# while the plane coefficients via Measurements.get_ground_plane() are given in camera frame,\n",
    "# where sampling along x and z axis would be the thing to do.\n",
    "def transform_plane(plane_model_source, T_source_target):\n",
    "    \"\"\"\n",
    "    Transforms plane coefficients [a,b,c,d]_source from plane_model_source represented in source frame\n",
    "    into plane coefficients [a,b,c,d]_target represented in target frame via T_source_target.\n",
    "\n",
    "    it works due to the identity of\n",
    "         [a,b,c,d]_source * p_source                      = 0  # p_source a point that lies in the source plane \n",
    "    <=>  [a,b,c,d]_source * (T_source_target  * p_target) = 0  # transform target points into source frame\n",
    "    <=> ([a,b,c,d]_source *  T_source_target) * p_target  = 0  # associativity of ()\n",
    "    <=>  [a,b,c,d]_target                     * p_target  = 0  # define [a,b,c,d]_target by content of bracket\n",
    "    \"\"\"\n",
    "    return plane_model_source.reshape(1, 4).dot(T_source_target)[0]  # unreshape\n",
    "\n",
    "\n",
    "start_index = 1430\n",
    "end_index = 1545\n",
    "\n",
    "dataset = Dataset()\n",
    "sequence = dataset.get_custom_sequence(start_index, end_index)\n",
    "\n",
    "plot = k3d.plot()\n",
    "\n",
    "# boundaries for ground plane in *LiDAR* frame\n",
    "x_min = 2.0\n",
    "x_max = 22.0\n",
    "y_min = -5.0\n",
    "y_max = 5.0\n",
    "# steps every 5 m should be sufficient as the ground plane is flat\n",
    "# so the steps along the x axis are 2.0, 7.0, 12.0, 17.0, 22.0\n",
    "# and for y axis -5.0, 0.0, 5.0\n",
    "x_step = 5.0\n",
    "y_step = 5.0\n",
    "\n",
    "plot += k3d.text(\"newworld\", position=[0.0, 0.0, 0.0], color=0x00FF00, size=0.5)\n",
    "plot += plot_axes(np.eye(4, dtype=np.float32))  # newworld\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# First I define the color array and initialize a counter for the colors\n",
    "colors = colors_qualitative_k3d\n",
    "j = 0\n",
    "\n",
    "# Iterate to every 10th frame\n",
    "for i in np.arange(start_index, end_index, 10):\n",
    "    \n",
    "    # Get the measurements for this frame\n",
    "    measurements = sequence[i]\n",
    "    \n",
    "    # Plot label and axes for the camera\n",
    "    T_newworld_camera = measurements.get_T_newworld_camera()\n",
    "    plot += k3d.text(str(i), position=T_newworld_camera[0:3, 3], color=colors[j], size=0.5)\n",
    "    plot += plot_axes(T_newworld_camera.astype(np.float32))\n",
    "    \n",
    "    # Get the ground plane in camera frame from measuremts and trasnform it in lidar frame\n",
    "    ground_plane_cf = measurements.get_ground_plane()\n",
    "    ground_plane_lf = transform_plane(ground_plane_cf, T_cam_lidar)\n",
    "    \n",
    "    # Compute the XYZs values for the ground plane model\n",
    "    Xs_lidar, Ys_lidar, Zs_lidar = get_plane_meshgrid(ground_plane_lf, x_min, x_max, y_min, y_max, x_step, y_step)\n",
    "    XYZs_lidar = np.vstack([Xs_lidar.ravel(), Ys_lidar.ravel(), Zs_lidar.ravel()]).T\n",
    "    \n",
    "    # Define the transformation from newworld to lidar frame by combining the camera transformations\n",
    "    T_newworld_lidar = T_newworld_camera.dot(T_cam_lidar)\n",
    "    \n",
    "    # Transform the XYZs values from lidar frame to newworld frame with this new transformation\n",
    "    XYZs_lidar_aug = np.hstack((XYZs_lidar, np.ones((XYZs_lidar.shape[0], 1))))\n",
    "    XYZs_lidar = T_newworld_lidar.dot(XYZs_lidar_aug.T).T\n",
    "    XYZs_lidar = XYZs_lidar[:, 0:3]\n",
    "    \n",
    "    # Finally, draw the mesh\n",
    "    indices = Triangulation(Xs_lidar.flatten(), Ys_lidar.flatten()).triangles.astype(np.uint32)\n",
    "    plt_mesh = k3d.mesh(XYZs_lidar.astype(np.float32), indices, color=colors[j], opacity=0.5)\n",
    "    plot += plt_mesh\n",
    "    \n",
    "    # Increment the color counter\n",
    "    j += 1\n",
    "    \n",
    "# raise NotImplementedError()\n",
    "plot.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33ae92e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8278001e7726b256b9d8fa66dd0f8a76",
     "grade": true,
     "grade_id": "test-precomputed-ground-plane-and-trajectory",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CELL REF: C1.10b\n",
    "vector_objects = np.asarray([o for o in plot.objects if o.type == \"Vectors\"])\n",
    "assert len(vector_objects) == 13, len(vector_objects)  # 12 camera frames and newworld frame\n",
    "\n",
    "mesh_objects = [o for o in plot.objects if o.type == \"Mesh\"]\n",
    "assert len(mesh_objects) == 12, len(mesh_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ed7f85",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "05fd7bb94fecf46f6622713c22b510cb",
     "grade": false,
     "grade_id": "wrap-up",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Wrap up\n",
    "That's it.\n",
    "You've shown us that you have the prerequisites to do actual processing on the dataset.\n",
    "Great job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
